# 实验设计文档：监管者Agent驱动的博弈实验

## 1. 研究背景与动机

### 1.1 问题发现

在MBTI-in-Thoughts项目的测试中发现：
- **低级别API（如gpt-4o-mini）**：能够有效突出不同MBTI人格在博弈中的行为差异
- **高级别API（如gpt-4o）**：无论赋予agent什么人格，都能快速识别博弈的最优解（如囚徒困境中的合作策略）

### 1.2 核心假设

通过引入**监管者Agent**动态生成更复杂的博弈问题变体，可以：
1. **放大人格差异**：更复杂的问题使高级模型难以立即识别最优解，从而更依赖人格特征
2. **提升实验质量**：动态生成的问题变体比静态问题更能揭示人格特征
3. **保持公平性**：确保出题agent的API等级 ≥ 做题agent的API等级

## 2. 实验设计

### 2.1 实验架构

```
┌─────────────────┐
│  Regulator      │  (高级API: gpt-4o)
│  Agent          │  → 生成问题变体
└────────┬────────┘
         │
         ↓
┌─────────────────┐
│  Variant Game   │  (变体博弈问题)
│  Structure      │
└────────┬────────┘
         │
         ↓
┌─────────────────┐     ┌─────────────────┐
│  Player Agent 1 │     │  Player Agent 2 │
│  (MBTI: INTJ)   │ ←→ │  (MBTI: ENFP)   │
│  (API: mini)    │     │  (API: mini)    │
└─────────────────┘     └─────────────────┘
```

### 2.2 实验变量

#### 自变量（Independent Variables）
1. **监管者模型**：gpt-4o, gpt-4-turbo等
2. **玩家模型**：gpt-4o-mini, gpt-3.5-turbo等
3. **MBTI人格组合**：16种MBTI类型的配对
4. **基础博弈类型**：囚徒困境、猎鹿博弈等
5. **变体类型**：complex, contextual, multi_stage

#### 因变量（Dependent Variables）
1. **合作率**：不同人格的合作/背叛比例
2. **策略一致性**：多轮中的策略稳定性
3. **沟通模式**：消息内容和意图分析
4. **得分差异**：不同人格的最终得分
5. **人格差异度**：不同人格在变体问题中的行为差异程度

### 2.3 实验条件

#### 条件1：监管者生成变体（实验组）
- 监管者：gpt-4o
- 玩家：gpt-4o-mini
- 使用动态生成的变体问题

#### 条件2：原始问题（对照组）
- 无监管者
- 玩家：gpt-4o-mini
- 使用原始静态问题

#### 条件3：高级模型玩家（对照组）
- 无监管者
- 玩家：gpt-4o
- 使用原始静态问题

### 2.4 实验流程

1. **问题生成阶段**
   - 监管者Agent接收基础博弈问题prompt
   - 生成3种类型的变体：complex, contextual, multi_stage
   - 验证变体的有效性和兼容性

2. **游戏执行阶段**
   - 两个玩家Agent使用生成的变体进行多轮博弈
   - 每轮包括：消息交换 → 行动选择 → 结果计算
   - 记录所有交互数据

3. **结果分析阶段**
   - 计算合作率、策略一致性等指标
   - 比较不同人格在变体问题中的表现差异
   - 与对照组进行对比分析

## 3. 预期结果

### 3.1 主要发现

1. **人格差异放大效应**
   - 在监管者生成的变体问题中，不同MBTI人格的行为差异更明显
   - 变体问题使高级模型难以立即识别最优解

2. **变体类型效应**
   - complex变体：增加策略复杂度，突出理性决策差异
   - contextual变体：增加情境因素，突出情感/价值差异
   - multi_stage变体：增加时间维度，突出长期规划差异

3. **API层级效应**
   - 监管者使用高级API生成的问题质量更高
   - 玩家使用低级API时，人格特征更明显

### 3.2 研究贡献

1. **方法论创新**：首次提出使用监管者Agent动态生成博弈问题变体
2. **实验发现**：揭示问题复杂度对MBTI人格表现的影响
3. **实用价值**：为多智能体系统设计提供新思路

## 4. 实验实施

### 4.1 实验规模

- **基础博弈**：8种（囚徒困境、猎鹿博弈等）
- **MBTI组合**：16种人格 × 16种人格 = 256种组合（可采样）
- **变体类型**：3种
- **重复次数**：每种条件至少3次
- **总实验数**：约8 × 256 × 3 × 3 = 18,432次（可优化采样）

### 4.2 成本估算

- **监管者调用**：每次实验1次（生成变体）
- **玩家调用**：每次实验约14次（7轮 × 2玩家）
- **意图分析**：每次实验约14次
- **总成本**：约$50-100（取决于采样策略）

### 4.3 时间安排

- **Week 1-2**：代码实现和调试
- **Week 3-4**：小规模预实验
- **Week 5-8**：大规模数据收集
- **Week 9-10**：数据分析和论文撰写

## 5. 评估指标

### 5.1 定量指标

1. **合作率（Cooperation Rate）**
   ```
   CR = (合作次数) / (总轮数)
   ```

2. **人格差异度（Personality Difference Score）**
   ```
   PDS = |CR_personality1 - CR_personality2|
   ```

3. **策略一致性（Strategy Consistency）**
   ```
   SC = 1 - (策略变化次数) / (总轮数 - 1)
   ```

4. **变体有效性（Variant Effectiveness）**
   ```
   VE = PDS_variant / PDS_base
   ```

### 5.2 定性分析

1. **消息内容分析**：不同人格的沟通风格
2. **策略演化分析**：多轮中的策略变化模式
3. **变体质量分析**：监管者生成的问题质量

## 6. 论文结构建议

### 6.1 标题建议

- "Regulator-Agent-Driven Game Variants: Amplifying Personality Differences in Multi-Agent Systems"
- "Dynamic Problem Generation for Personality-Aware Multi-Agent Games"
- "Enhancing MBTI Personality Expression through Regulator-Generated Game Variants"

### 6.2 章节结构

1. **Introduction**
   - 背景：MBTI人格在多智能体系统中的作用
   - 问题：高级模型掩盖人格差异
   - 贡献：监管者Agent方法

2. **Related Work**
   - MBTI人格在AI中的应用
   - 博弈论与多智能体系统
   - 动态问题生成

3. **Methodology**
   - 监管者Agent设计
   - 变体生成机制
   - 实验设置

4. **Experiments**
   - 实验设计
   - 结果分析
   - 消融实验

5. **Discussion**
   - 发现与启示
   - 局限性
   - 未来工作

6. **Conclusion**

## 7. 潜在会议

### 7.1 顶级会议（Tier 1）
- **NeurIPS**：神经信息处理系统会议
- **ICML**：国际机器学习会议
- **AAAI**：人工智能协会年会

### 7.2 相关会议（Tier 2）
- **AAMAS**：自主智能体和多智能体系统
- **IJCAI**：国际人工智能联合会议
- **UAI**：不确定性人工智能

## 8. 风险与缓解

### 8.1 技术风险
- **风险**：变体生成质量不稳定
- **缓解**：多轮生成 + 质量验证机制

### 8.2 成本风险
- **风险**：实验成本超预算
- **缓解**：采样策略 + 分批实验

### 8.3 时间风险
- **风险**：实验周期过长
- **缓解**：并行实验 + 自动化脚本

## 9. 下一步行动

1. ✅ 完成代码框架搭建
2. ⏳ 实现监管者Agent
3. ⏳ 实现变体生成器
4. ⏳ 集成到游戏运行框架
5. ⏳ 小规模预实验
6. ⏳ 大规模数据收集
7. ⏳ 数据分析和论文撰写
